{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to define for each experiment ###\n",
    "\n",
    "### import file ###\n",
    "name = 'clinical_insitucomplex_MERGED_lowgain'\n",
    "data_path = f'C:/Users/jlesinski/Desktop/Biochemistry/biochemtofetch/Plate Reader/15082023/{name}.csv'\n",
    "output_path = f'C:/Users/jlesinski/Desktop/Biochemistry/biochemgraphs/{name}.jpg'\n",
    "title_name_graph = 'Clinical Pre-complexed vs In-situ - SHERLOCK Criteria'\n",
    "\n",
    "### plate layout ###\n",
    "well_names = {'A1':'In-situ Negative00', 'A2':'In-situ Negative01', 'A3':'In-situ Negative02',\n",
    "            'B1':'In-situ Negative10', 'B2':'In-situ Negative11', 'B3':'In-situ Negative12',\n",
    "            'C1':'In-situ Negative20', 'C2':'In-situ Negative21', 'C3':'In-situ Negative22',\n",
    "            'D1':'In-situ Negative30', 'D2':'In-situ Negative31', 'D3':'In-situ Negative32',\n",
    "            'E1':'In-situ Negative40', 'E2':'In-situ Negative41', 'E3':'In-situ Negative42',\n",
    "            'F1':'In-situ Negative50', 'F2':'In-situ Negative51', 'F3':'In-situ Negative52',\n",
    "            'G1':'In-situ Negative60', 'G2':'In-situ Negative61', 'G3':'In-situ Negative62',\n",
    "            'H1':'In-situ Negative70', 'H2':'In-situ Negative71', 'H3':'In-situ Negative72',\n",
    "            'I1':'Pre-complexed Negative00', 'I2':'Pre-complexed Negative01', 'I3':'Pre-complexed Negative02',\n",
    "            'J1':'Pre-complexed Negative10', 'J2':'Pre-complexed Negative11', 'J3':'Pre-complexed Negative12',\n",
    "            'K1':'Pre-complexed Negative20', 'K2':'Pre-complexed Negative21', 'K3':'Pre-complexed Negative22',\n",
    "            'L1':'Pre-complexed Negative30', 'L2':'Pre-complexed Negative31', 'L3':'Pre-complexed Negative32',\n",
    "            'M1':'Pre-complexed Negative40', 'M2':'Pre-complexed Negative41', 'M3':'Pre-complexed Negative42',\n",
    "            'N1':'Pre-complexed Negative50', 'N2':'Pre-complexed Negative51', 'N3':'Pre-complexed Negative52',\n",
    "            'O1':'Pre-complexed Negative60', 'O2':'Pre-complexed Negative61', 'O3':'Pre-complexed Negative62',\n",
    "            'P1':'Pre-complexed Negative70', 'P2':'Pre-complexed Negative71', 'P3':'Pre-complexed Negative72',\n",
    "            'A4':'21.7 Pre-complexed', 'A5':'21.7 Pre-complexed1', 'A6':'21.7 Pre-complexed2',\n",
    "            'B4':'32.7 Pre-complexed', 'B5':'32.7 Pre-complexed1', 'B6':'32.7 Pre-complexed2',\n",
    "            'C4':'29.4 Pre-complexed', 'C5':'29.4 Pre-complexed1', 'C6':'29.4 Pre-complexed2',\n",
    "            'D4':'33.7 Pre-complexed', 'D5':'33.7 Pre-complexed1', 'D6':'33.7 Pre-complexed2',\n",
    "            'E4':'30.8 Pre-complexed', 'E5':'30.8 Pre-complexed1', 'E6':'30.8 Pre-complexed2',\n",
    "            'F4':'28.4 Pre-complexed', 'F5':'28.4 Pre-complexed1', 'F6':'28.4 Pre-complexed2',\n",
    "            'G4':'21.3 Pre-complexed', 'G5':'21.3 Pre-complexed1', 'G6':'21.3 Pre-complexed2',\n",
    "            'H4':'34.4 Pre-complexed', 'H5':'34.4 Pre-complexed1', 'H6':'34.4 Pre-complexed2',\n",
    "            'A7':'21.7 In-situ', 'A8':'21.7 In-situ1', 'A9':'21.7 In-situ2',\n",
    "            'B7':'32.7 In-situ', 'B8':'32.7 In-situ1', 'B9':'32.7 In-situ2',\n",
    "            'C7':'29.4 In-situ', 'C8':'29.4 In-situ1', 'C9':'29.4 In-situ2',\n",
    "            'D7':'33.7 In-situ', 'D8':'33.7 In-situ1', 'D9':'33.7 In-situ2',\n",
    "            'E7':'30.8 In-situ', 'E8':'30.8 In-situ1', 'E9':'30.8 In-situ2',\n",
    "            'F7':'28.4 In-situ', 'F8':'28.4 In-situ1', 'F9':'28.4 In-situ2',\n",
    "            'G7':'21.3 In-situ', 'G8':'21.3 In-situ1', 'G9':'21.3 In-situ2',\n",
    "            'H7':'34.4 In-situ', 'H8':'34.4 In-situ1', 'H9':'34.4 In-situ2'}\n",
    "\n",
    "replicate_names = ['In-situ Negative0', 'In-situ Negative1','In-situ Negative2','In-situ Negative3','In-situ Negative4','In-situ Negative5','In-situ Negative6','In-situ Negative7','Pre-complexed Negative0', 'Pre-complexed Negative1','Pre-complexed Negative2','Pre-complexed Negative3','Pre-complexed Negative4','Pre-complexed Negative5','Pre-complexed Negative6','Pre-complexed Negative7', '21.7 Pre-complexed', '32.7 Pre-complexed', '29.4 Pre-complexed', '33.7 Pre-complexed', '30.8 Pre-complexed', '28.4 Pre-complexed', '21.3 Pre-complexed', '34.4 Pre-complexed', '21.7 In-situ', '32.7 In-situ', '29.4 In-situ', '33.7 In-situ', '30.8 In-situ', '28.4 In-situ', '21.3 In-situ', '34.4 In-situ']\n",
    "'Pre-complexed Negative', 'Pre-complexed Negative1','Pre-complexed Negative2','Pre-complexed Negative3','Pre-complexed Negative4','Pre-complexed Negative5','Pre-complexed Negative6','Pre-complexed Negative7'\n",
    "### parameters to control ###\n",
    "stdevs_for_TTR = 3\n",
    "number_consecutive_for_TTR = 3\n",
    "conc_vector = [21.63, 32.70, 29.38, 33.66, 30.80, 28.25, 21.26, 34.39]\n",
    "replicate_count = 3\n",
    "\n",
    "### differentiating between 2 to compare ###\n",
    "thing0 = 'Pre-complexed'\n",
    "thing1 = 'In-situ'\n",
    "number_to_diff_bt = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions ###\n",
    "def convert_to_mins(time):\n",
    "    time = time.split(':')\n",
    "    time = int(time[0])*60 + int(time[1]) + int(time[2])/60\n",
    "    return time\n",
    "\n",
    "def consective_values(input_list, target_value, num_consective):\n",
    "    consec = 0\n",
    "    for i in range(len(input_list)):\n",
    "        if input_list[i] == target_value:\n",
    "            consec += 1\n",
    "        else:\n",
    "            consec = 0\n",
    "        if consec == num_consective:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def repeat_list(l,repeats):\n",
    "    new_list = []\n",
    "    for i in l:\n",
    "        new_list.append([i]*repeats)\n",
    "    return new_list\n",
    "\n",
    "def repeat_list_flattened(l,repeats):\n",
    "    new_list = []\n",
    "    for i in l:\n",
    "        new_list.extend([i]*repeats)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dataframe ###\n",
    "df = pd.read_csv(data_path, skiprows=90, encoding = \"ISO-8859-1\")\n",
    "\n",
    "### remane columns ###\n",
    "df = df.rename(columns=well_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chop off the end of the dataframe ###\n",
    "df = df.dropna(subset=['Time'])\n",
    "df = df.dropna(axis=1, how='all')\n",
    "for col in df.columns:\n",
    "    if col == 'Time':\n",
    "        pass\n",
    "    elif col not in well_names.values():\n",
    "        df = df.drop(columns=col)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "### Make time column into minutes ###\n",
    "df['Time'] = df['Time'].apply(convert_to_mins)\n",
    "df = df[df['Time'] <= 90]\n",
    "\n",
    "# ### Background subtraction/ Zeroing ###\n",
    "df_temp = df\n",
    "df_temp = df_temp.drop(columns=['Time'])\n",
    "first_row_value = df_temp.iloc[0]\n",
    "df_temp = df_temp.subtract(first_row_value)\n",
    "df_temp['Time'] = df['Time']\n",
    "df = df_temp\n",
    "df_to_plot = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TTR Setup ######## - first part BUT only for 1 negative replicate set\n",
    "### bundle replicates - by name ###\n",
    "# well_names_value_vector = []\n",
    "# for key, value in well_names.items():\n",
    "#     well_names_value_vector.append(value)\n",
    "# composite_list_wellnames = [well_names_value_vector[x:x+replicate_count] for x in range(0, len(well_names_value_vector),replicate_count)]\n",
    "\n",
    "# ### get mean and std of replicate set ###\n",
    "# mean_vector = []\n",
    "# std_vector = []\n",
    "# for rep in composite_list_wellnames:\n",
    "#     multiple_lists_temp = []\n",
    "#     for sample in rep:\n",
    "#         print(sample)\n",
    "        # multiple_lists_temp.append(np.array(df_to_plot[sample]))\n",
    "    # arrays = [np.array(x) for x in multiple_lists_temp]\n",
    "    # std_vector.append([stdevs_for_TTR*np.std(k) for k in zip(*arrays)])\n",
    "#     mean_vector.append([np.mean(k) for k in zip(*arrays)])\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# mean_vector = np.array(mean_vector)\n",
    "# std_vector = np.array(std_vector)\n",
    "# mean_vector = np.transpose(mean_vector)\n",
    "# std_vector = np.transpose(std_vector)\n",
    "# df_mean = pd.DataFrame(mean_vector, columns = replicate_names)\n",
    "# df_std = pd.DataFrame(std_vector, columns = replicate_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TTR Setup ######## - for multiple negative replicate sets\n",
    "### bundle replicates - by name ###\n",
    "well_names_value_vector = []\n",
    "for key, value in well_names.items():\n",
    "    well_names_value_vector.append(value)\n",
    "composite_list_wellnames = [well_names_value_vector[x:x+replicate_count] for x in range(0, len(well_names_value_vector),replicate_count)]\n",
    "\n",
    "### make negatives list ###\n",
    "neg_list = []\n",
    "for i in composite_list_wellnames:\n",
    "    for j in i:\n",
    "        if 'neg' in j or 'Neg' in j:\n",
    "            neg_list.append(j)\n",
    "\n",
    "### split neglist into thing0 and thing1 ###\n",
    "thing0_neglist = []\n",
    "thing1_neglist = []\n",
    "for i in neg_list:\n",
    "    if thing0 in i:\n",
    "        thing0_neglist.append(i)\n",
    "    elif thing1 in i:\n",
    "        thing1_neglist.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "### for negative df ###\n",
    "df_neg_thing0 = df[thing0_neglist]\n",
    "df_neg_thing1 = df[thing1_neglist]\n",
    "\n",
    "### get point slope vector for thing0/thing1 for Negatives ###\n",
    "cycle_time = df['Time'][1] - df['Time'][0]\n",
    "df_point_slope_thing0 = pd.DataFrame()\n",
    "for column in df_neg_thing0.columns[:]:\n",
    "    df_point_slope_thing0[column] = np.gradient(df_neg_thing0[column], cycle_time)\n",
    "df_point_slope_thing1 = pd.DataFrame()\n",
    "for column in df_neg_thing1.columns[:]:\n",
    "    df_point_slope_thing1[column] = np.gradient(df_neg_thing1[column], cycle_time)\n",
    "\n",
    "### get point slope vector for thing0/thing1 for Posatives ###\n",
    "df_point_slope_thing0_pos = pd.DataFrame()\n",
    "for column in df_to_plot.columns[:]:\n",
    "    if 'neg' in column or 'Neg' in column or 'Negative' in column or 'negative' in column:\n",
    "        pass\n",
    "    elif thing0 in column:\n",
    "        df_point_slope_thing0_pos[column] = np.gradient(df_to_plot[column], cycle_time)\n",
    "    else:\n",
    "        pass\n",
    "df_point_slope_thing1_pos = pd.DataFrame()\n",
    "for column in df_to_plot.columns[:]:\n",
    "    if 'neg' in column or 'Neg' in column or 'Negative' in column or 'negative' in column:\n",
    "        pass\n",
    "    elif thing1 in column:\n",
    "        df_point_slope_thing1_pos[column] = np.gradient(df_to_plot[column], cycle_time)\n",
    "    else:\n",
    "        pass\n",
    "df_point_slope_thing_both_pos = pd.concat([df_point_slope_thing0_pos, df_point_slope_thing1_pos], axis=1, sort=False)\n",
    "\n",
    "### get max point slope vector for thing0/thing1 for Negatives ###\n",
    "df_point_slope_thing0_max = df_point_slope_thing0.max(axis=1)\n",
    "df_point_slope_thing1_max = df_point_slope_thing1.max(axis=1)\n",
    "\n",
    "### get standard deviation point slope vector for thing0/thing1 for Negatives ###\n",
    "df_point_slope_thing0_std = df_point_slope_thing0.std(axis=1)\n",
    "df_point_slope_thing1_std = df_point_slope_thing1.std(axis=1)\n",
    "\n",
    "### create negative intersection vector - max + stdevs_for_TTR*std ###\n",
    "df_point_slope_thing0_intersection_vector = df_point_slope_thing0_max + stdevs_for_TTR*df_point_slope_thing0_std\n",
    "df_point_slope_thing1_intersection_vector = df_point_slope_thing1_max + stdevs_for_TTR*df_point_slope_thing1_std\n",
    "\n",
    "# ### find intersection times ###\n",
    "time_of_escape = []\n",
    "time_of_escape1 = []\n",
    "for column in df_point_slope_thing_both_pos.columns[:]:\n",
    "    if 'neg' in column or 'Neg' in column or 'Negative' in column or 'negative' in column:\n",
    "        pass\n",
    "    elif thing0 in column:\n",
    "        tally = []\n",
    "        for (index,values),(indexn,values_neg) in zip(df_point_slope_thing_both_pos[column].iteritems(),df_point_slope_thing0_intersection_vector.iteritems()):\n",
    "            if values > values_neg:\n",
    "                tally.append(1)\n",
    "                if consective_values(tally, 1, number_consecutive_for_TTR) == True:\n",
    "                    te = index*cycle_time\n",
    "                    time_of_escape.append(te)\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                tally.append(0)\n",
    "                if indexn == (len(df_point_slope_thing_both_pos)-1):\n",
    "                    time_of_escape.append('No TTR')\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "    elif thing1 in column:\n",
    "        tally = []\n",
    "        for (index,values),(indexn,values_neg) in zip(df_point_slope_thing_both_pos[column].iteritems(),df_point_slope_thing1_intersection_vector.iteritems()):\n",
    "            if values > values_neg:\n",
    "                tally.append(1)\n",
    "                if consective_values(tally, 1, number_consecutive_for_TTR) == True:\n",
    "                    te = index*cycle_time\n",
    "                    time_of_escape1.append(te)\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                tally.append(0)\n",
    "                if indexn == (len(df_point_slope_thing_both_pos)-1):\n",
    "                    time_of_escape1.append('No TTR')\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "# composite_list_wellnames = [time_of_escape[x:x+replicate_count] for x in range(0, len(time_of_escape),replicate_count)]\n",
    "# composite_list_wellnames = np.array(composite_list_wellnames)\n",
    "# composite_list_wellnames = np.transpose(composite_list_wellnames)\n",
    "\n",
    "# composite_list_wellnames1 = [time_of_escape1[x:x+replicate_count] for x in range(0, len(time_of_escape1),replicate_count)]\n",
    "# composite_list_wellnames1 = np.array(composite_list_wellnames1)\n",
    "# composite_list_wellnames1 = np.transpose(composite_list_wellnames1)\n",
    "\n",
    "# replicate_names_temp = []\n",
    "# for name in replicate_names:\n",
    "#     if 'neg' in name or 'Neg' in name or thing1 in name:\n",
    "#         pass\n",
    "#     else:\n",
    "#         replicate_names_temp.append(name)\n",
    "# # replicate_names = replicate_names_temp\n",
    "# df_ttr = pd.DataFrame(data = composite_list_wellnames, columns = replicate_names_temp)\n",
    "\n",
    "# replicate_names_temp1 = []\n",
    "# for name in replicate_names:\n",
    "#     if 'neg' in name or 'Neg' in name or thing0 in name:\n",
    "#         pass\n",
    "#     else:\n",
    "#         replicate_names_temp1.append(name)\n",
    "# # replicate_names1 = replicate_names_temp1\n",
    "# df_ttr1 = pd.DataFrame(data = composite_list_wellnames1, columns = replicate_names_temp1)\n",
    "\n",
    "# df_to_plot = pd.concat([df_ttr, df_ttr1], axis=1, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare for plotting - conc vector vs time of escape ###\n",
    "conc_vector_rep = repeat_list_flattened(conc_vector, replicate_count)\n",
    "composite_list = np.array(conc_vector_rep)\n",
    "conc_vector = np.transpose(composite_list)\n",
    "\n",
    "df_to_plot = pd.DataFrame()\n",
    "df_to_plot['Concentration'] = conc_vector\n",
    "df_to_plot['TTR_'+thing0] = time_of_escape\n",
    "df_to_plot['TTR_'+thing1] = time_of_escape1\n",
    "df_to_plot = df_to_plot.replace('No TTR', df['Time'].iloc[-1]+3*cycle_time)\n",
    "\n",
    "### average every 3 elements in df_to_plot ###\n",
    "df_to_plot_temp = pd.DataFrame()\n",
    "for i in range(0,len(conc_vector),replicate_count):\n",
    "    df_to_plot_temp = df_to_plot_temp.append(df_to_plot.iloc[i:i+replicate_count].mean(), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####### Heatmap plot TTR #######\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# for column in df_to_plot.columns[:]:\n",
    "#     if not (thing0 in column or thing1 in column):\n",
    "#         print(column)\n",
    "#         continue\n",
    "#     elif thing0 in column:\n",
    "#         marker = 'o'\n",
    "#         palette = 'green'\n",
    "#     elif thing1 in column:\n",
    "#         marker = '<'\n",
    "#         palette = 'blue'\n",
    "#     else:\n",
    "#         print('error')\n",
    "    \n",
    "#     sns.heatmap(data=df_to_plot,\n",
    "#                 ax=ax1,\n",
    "#                 # hue='red',\n",
    "#                 # style='crRNA',\n",
    "#                 # ci=99.7,          \n",
    "#                 #errorbar = ('ci',95),\n",
    "#                 #s=ss,\n",
    "#                 alpha = 0.5,\n",
    "#                 label = column)\n",
    "\n",
    "# bbox_inches='tight'\n",
    "# fig.savefig(output_path, bbox_inches='tight', dpi = 500)\n",
    "\n",
    "####### Scatter plot TTR #######\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# for column in df_to_plot.columns[:]:\n",
    "#     if not (thing0 in column or thing1 in column):\n",
    "#         print(column)\n",
    "#         continue\n",
    "#     elif thing0 in column:\n",
    "#         marker = 'o'\n",
    "#         palette = 'green'\n",
    "#     elif thing1 in column:\n",
    "#         marker = '<'\n",
    "#         palette = 'blue'\n",
    "#     else:\n",
    "#         print('error')\n",
    "    \n",
    "#     sns.scatterplot(data=df_to_plot,\n",
    "#                 x='Concentration',\n",
    "#                 y=column,\n",
    "#                 ax=ax1,\n",
    "#                 palette= palette,\n",
    "#                 # hue='red',\n",
    "#                 # style='crRNA',\n",
    "#                 # ci=99.7,          \n",
    "#                 #errorbar = ('ci',95),\n",
    "#                 marker = marker,\n",
    "#                 #s=ss,\n",
    "#                 alpha = 0.5,\n",
    "#                 label = column)\n",
    "\n",
    "# # sns.set_palette(\"magma\", n_colors = len(replicate_names_concs))\n",
    "# ax1.set_xlabel('Concentration [Ct]',fontsize = 5)\n",
    "# ax1.set_ylabel('TTR [Minutes]',fontsize = 5)\n",
    "# ax1.legend(fontsize = 5)\n",
    "# ax1.set_title(title_name_graph,fontsize = 7)\n",
    "# # ax1.set_yticks(np.arange(0,10000,1000))\n",
    "# ax1.tick_params(labelsize=5)\n",
    "\n",
    "# # ax1.figsize=(15,10)\n",
    "\n",
    "# bbox_inches='tight'\n",
    "# fig.savefig(output_path, bbox_inches='tight', dpi = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos11_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m########################### From nathan ##########################################\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m samples \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39m11\u001b[39m\u001b[39m'\u001b[39m: pos11_data, \n\u001b[0;32m      4\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m12\u001b[39m\u001b[39m'\u001b[39m: pos12_data,\n\u001b[0;32m      5\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m13\u001b[39m\u001b[39m'\u001b[39m: pos13_data,\n\u001b[0;32m      6\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m14\u001b[39m\u001b[39m'\u001b[39m: pos14_data,\n\u001b[0;32m      7\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m15\u001b[39m\u001b[39m'\u001b[39m: pos15_data,\n\u001b[0;32m      8\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m16\u001b[39m\u001b[39m'\u001b[39m: pos16_data,\n\u001b[0;32m      9\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m17\u001b[39m\u001b[39m'\u001b[39m: pos17_data,\n\u001b[0;32m     10\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m18\u001b[39m\u001b[39m'\u001b[39m: pos18_data}\n\u001b[0;32m     12\u001b[0m neg_ct_symbol \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     13\u001b[0m neg_ct_value \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pos11_data' is not defined"
     ]
    }
   ],
   "source": [
    "########################### From nathan ##########################################\n",
    "\n",
    "samples = {'11': pos11_data, \n",
    "           '12': pos12_data,\n",
    "           '13': pos13_data,\n",
    "           '14': pos14_data,\n",
    "           '15': pos15_data,\n",
    "           '16': pos16_data,\n",
    "           '17': pos17_data,\n",
    "           '18': pos18_data}\n",
    "\n",
    "neg_ct_symbol = 'X'\n",
    "neg_ct_value = 0.0\n",
    "neg_tts_value = 0.0\n",
    "\n",
    "samples_quot_tts_mean = {}\n",
    "samples_bhq_tts_mean = {}\n",
    "\n",
    "samples_quot_tts_stdev = {}\n",
    "samples_bhq_tts_stdev = {}\n",
    "\n",
    "samples_quot_tts_ind = {}\n",
    "samples_bhq_tts_ind = {}\n",
    "\n",
    "use_pos_stdev = False\n",
    "\n",
    "for k,v in samples.items():\n",
    "    print(k)\n",
    "    qtimes, quottts = clinical_tts(v['quotient'], allneg_data['quotient_stats'], use_pos_stdev=use_pos_stdev)\n",
    "    bhqtimes, bhqtts = clinical_tts(v['fam_bhq_data'], allneg_data['fam_bhq_stats'], use_pos_stdev=use_pos_stdev)\n",
    "    print(qtimes)\n",
    "\n",
    "    samples_quot_tts_mean[k] = quottts['mean']\n",
    "    samples_bhq_tts_mean[k] = bhqtts['mean']\n",
    "    samples_quot_tts_stdev[k] = quottts['std']\n",
    "    samples_bhq_tts_stdev[k] = bhqtts['std']\n",
    "    samples_quot_tts_ind[k] = list(qtimes.values())\n",
    "    samples_bhq_tts_ind[k] = list(bhqtimes.values())\n",
    "\n",
    "\n",
    "heatmap_data_inv2 = np.array([[df_to_plot['TTR_'+thing0].loc[0],df_to_plot['TTR_'+thing0].loc[1],df_to_plot['TTR_'+thing0].loc[2]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[0],df_to_plot['TTR_'+thing1].loc[1],df_to_plot['TTR_'+thing1].loc[2]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[3],df_to_plot['TTR_'+thing0].loc[4],df_to_plot['TTR_'+thing0].loc[5]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[3],df_to_plot['TTR_'+thing1].loc[4],df_to_plot['TTR_'+thing1].loc[5]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[6],df_to_plot['TTR_'+thing0].loc[7],df_to_plot['TTR_'+thing0].loc[8]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[6],df_to_plot['TTR_'+thing1].loc[7],df_to_plot['TTR_'+thing1].loc[8]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[9],df_to_plot['TTR_'+thing0].loc[10],df_to_plot['TTR_'+thing0].loc[11]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[9],df_to_plot['TTR_'+thing1].loc[10],df_to_plot['TTR_'+thing1].loc[11]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[12],df_to_plot['TTR_'+thing0].loc[13],df_to_plot['TTR_'+thing0].loc[14]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[12],df_to_plot['TTR_'+thing1].loc[13],df_to_plot['TTR_'+thing1].loc[14]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[15],df_to_plot['TTR_'+thing0].loc[16],df_to_plot['TTR_'+thing0].loc[17]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[15],df_to_plot['TTR_'+thing1].loc[16],df_to_plot['TTR_'+thing1].loc[17]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[18],df_to_plot['TTR_'+thing0].loc[19],df_to_plot['TTR_'+thing0].loc[20]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[18],df_to_plot['TTR_'+thing1].loc[19],df_to_plot['TTR_'+thing1].loc[20]],\n",
    "                            [df_to_plot['TTR_'+thing0].loc[21],df_to_plot['TTR_'+thing0].loc[22],df_to_plot['TTR_'+thing0].loc[23]],\n",
    "                            [df_to_plot['TTR_'+thing1].loc[21],df_to_plot['TTR_'+thing1].loc[22],df_to_plot['TTR_'+thing1].loc[23]],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value],\n",
    "                            [neg_ct_value, neg_tts_value, neg_tts_value]\n",
    "                            ])\n",
    "\n",
    "heatmap_data_inv2 = np.nan_to_num(heatmap_data_inv2)\n",
    "\n",
    "ctarr = np.array([[cts['11']],\n",
    " [cts['12']],\n",
    " [cts['13']],\n",
    " [cts['14']],\n",
    " [cts['15']],\n",
    " [cts['16']],\n",
    " [cts['17']],\n",
    " [cts['18']],\n",
    " [neg_ct_value],\n",
    "    [neg_ct_value],\n",
    "    [neg_ct_value],\n",
    "    [neg_ct_value],\n",
    "    [neg_ct_value],\n",
    "    [neg_ct_value],\n",
    "    [neg_ct_value],\n",
    "    [neg_ct_value]]\n",
    ")\n",
    "\n",
    "\n",
    "sample_tick_labels = ['Positive 1',\n",
    "                      'Positive 2',\n",
    "                      'Positive 3',\n",
    "                      'Positive 4',\n",
    "                      'Positive 5',\n",
    "                      'Positive 6',\n",
    "                      'Positive 7',\n",
    "                      'Positive 8',\n",
    "                      'Negative 1',\n",
    "                      'Negative 2',\n",
    "                      'Negative 3',\n",
    "                      'Negative 4',\n",
    "                      'Negative 5',\n",
    "                      'Negative 6',\n",
    "                      'Negative 7',\n",
    "                      'Negative 8']\n",
    "\n",
    "\n",
    "\n",
    "########################### From nathan ##########################################\n",
    "\n",
    "intesample_space = 3\n",
    "intrasample_space = .75\n",
    "\n",
    "intersample_plotspace = .05\n",
    "intrasample_plotspace = .15\n",
    "\n",
    "not_significant_symbol = 'Neg'\n",
    "\n",
    "ocolormap = mpl.colormaps['Blues']\n",
    "colors = ocolormap(np.linspace(0.2, 1.0, 8192))\n",
    "colors[:,3] = 0.6\n",
    "colors[0] = [255/255, 109/255, 106/255, .1]\n",
    "colormap = mpl.colors.ListedColormap(colors)\n",
    "\n",
    "#colors = colormap(np.linspace(0, 1, len(data_dict.keys())))\n",
    "\n",
    "\n",
    "\n",
    "Z = np.random.rand(18, 3)\n",
    "Z= heatmap_data_inv2\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(7*cm, 16.8*cm), gridspec_kw={'width_ratios': [1, 3]}, dpi=200)\n",
    "\n",
    "vmn = sorted(set(Z.flatten()))[1] - 1\n",
    "vmx = sorted(set(Z.flatten()))[-1]\n",
    "\n",
    "vmnct = sorted(set(ctarr.flatten()))[1] - .01\n",
    "vmxct = sorted(set(ctarr.flatten()))[-1]\n",
    "\n",
    "c1 = ax[0].pcolormesh(ctarr, cmap=colormap, shading='flat', vmin=vmnct, vmax=vmxct)\n",
    "c2 = ax[1].pcolormesh(Z, cmap=colormap, shading='flat', vmin=vmn, vmax=vmx)\n",
    "\n",
    "#print('color range: ', np.multiply(), 255), ' to ', np.multiply(colormap(1), 255))\n",
    "#print('neg color: ', colormap(0))\n",
    "#print(f'pcr range is {} to {}')\n",
    "\n",
    "\n",
    "# Reset all ticks on all the axis and make spines invisible\n",
    "\n",
    "ax[0].set_xticks([], minor=True)\n",
    "ax[0].set_xticks([], minor=False)\n",
    "ax[0].set_yticks([], minor=True)\n",
    "ax[0].set_yticks([], minor=False)\n",
    "\n",
    "ax[0].spines[:].set_visible(False)\n",
    "\n",
    "ax[1].set_xticks([], minor=True)\n",
    "ax[1].set_xticks([], minor=False)\n",
    "ax[1].set_yticks([], minor=True)\n",
    "ax[1].set_yticks([], minor=False)\n",
    "\n",
    "ax[1].spines[:].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "# Now remake the ticks as I want them\n",
    "\n",
    "ax[1].set_xticks(np.arange(Z.shape[1]), minor=True)\n",
    "ax[1].set_yticks(np.arange(Z.shape[0]/2)*2, minor=True)\n",
    "ax[1].set_yticks(np.arange(Z.shape[0]/2)*2 + 1, minor=False)\n",
    "#ax[1].set_xticks(np.arange(Z.shape[1])+0.5, minor=False, labels=['Replicate 1', 'Replicate 2', 'Replicate 3'], rotation=45, ha='center', va='bottom')\n",
    "\n",
    "ax[0].set_yticks(np.arange(ctarr.shape[0]), minor=True)\n",
    "ax[0].set_yticks(np.arange(ctarr.shape[0])+0.5, minor=False, labels=sample_tick_labels)\n",
    "#ax[0].set_xticks(np.arange(ctarr.shape[1])+0.5, minor=False, labels=['PCR Ct'], rotation=45, ha='center', va='bottom')\n",
    "\n",
    "\n",
    "\n",
    "# Invert the y axis\n",
    "ax[0].invert_yaxis()\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "\n",
    "# Turn off markins I dont want\n",
    "\n",
    "ax[1].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=False,\n",
    "    labeltop=True) # labels along the bottom edge are off\n",
    "\n",
    "#ax[1].xaxis.tick_top()\n",
    "\n",
    "#ax[1].xaxis.set_ticks_position('none') \n",
    "#Ax[1].yaxis.set_ticks_position('none')\n",
    "\n",
    "ax[0].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=True,\n",
    "    labeltop=True) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "# Turn the girdlines one\n",
    "ax[1].grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=intesample_space, snap=True)\n",
    "ax[1].grid(which=\"major\", color=\"w\", linestyle='-', linewidth=intrasample_space, snap=True)\n",
    "ax[0].grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=intesample_space, snap=True)\n",
    "\n",
    "\n",
    "# Now we label squares:\n",
    "\n",
    "for row in range(Z.shape[0]):\n",
    "    for col in range(Z.shape[1]):\n",
    "        s = not_significant_symbol if Z[row, col] < 0.05 else f'{Z[row, col]:.0f}'\n",
    "            \n",
    "        ax[1].text(col + 0.5, row + 0.5, s,\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            fontsize=7,\n",
    "            color='k')\n",
    "\n",
    "for row in range(ctarr.shape[0]):\n",
    "    for col in range(ctarr.shape[1]):\n",
    "        s = not_significant_symbol if ctarr[row, col] < 0.05 else f'{ctarr[row, col]:.2f}'\n",
    "            \n",
    "        ax[0].text(col + 0.5,\n",
    "            row + 0.5,\n",
    "            s,\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            fontsize=7,\n",
    "            color='k')\n",
    "\n",
    "\n",
    "print(ax[1].get_xlim(), ax[1].get_ylim())\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./charts/5A_table.png', dpi=2000)\n",
    "fig.savefig('./charts/5A_table.svg', dpi=2000)\n",
    "fig.savefig('./charts/5A_table.eps', dpi=2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FRET_CRISPR_Reporter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
